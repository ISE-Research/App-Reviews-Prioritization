{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0-OKNfedYzR",
        "outputId": "bcfccf8c-bf93-4084-b1c7-e2ebf781b9c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost)\n",
            "  Downloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl (190.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.22.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-nccl-cu12-2.22.3\n",
            "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
            "Best Parameters: {'colsample_bytree': 0.6, 'eta': 0.01, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 300, 'subsample': 1.0}\n",
            "Best Score: 0.7679486254188979\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.82      4809\n",
            "           1       0.67      0.79      0.73      2832\n",
            "\n",
            "    accuracy                           0.78      7641\n",
            "   macro avg       0.77      0.78      0.77      7641\n",
            "weighted avg       0.79      0.78      0.78      7641\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.77      0.81      4745\n",
            "           1       0.67      0.78      0.73      2895\n",
            "\n",
            "    accuracy                           0.78      7640\n",
            "   macro avg       0.76      0.78      0.77      7640\n",
            "weighted avg       0.79      0.78      0.78      7640\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81      4745\n",
            "           1       0.67      0.79      0.73      2895\n",
            "\n",
            "    accuracy                           0.77      7640\n",
            "   macro avg       0.76      0.78      0.77      7640\n",
            "weighted avg       0.79      0.77      0.78      7640\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.78      0.81      4729\n",
            "           1       0.68      0.78      0.73      2911\n",
            "\n",
            "    accuracy                           0.78      7640\n",
            "   macro avg       0.77      0.78      0.77      7640\n",
            "weighted avg       0.79      0.78      0.78      7640\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.77      0.81      4852\n",
            "           1       0.66      0.79      0.72      2788\n",
            "\n",
            "    accuracy                           0.78      7640\n",
            "   macro avg       0.76      0.78      0.77      7640\n",
            "weighted avg       0.79      0.78      0.78      7640\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.78      0.82      4687\n",
            "           1       0.69      0.80      0.74      2953\n",
            "\n",
            "    accuracy                           0.79      7640\n",
            "   macro avg       0.78      0.79      0.78      7640\n",
            "weighted avg       0.80      0.79      0.79      7640\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.78      0.82      4731\n",
            "           1       0.69      0.78      0.73      2909\n",
            "\n",
            "    accuracy                           0.78      7640\n",
            "   macro avg       0.77      0.78      0.77      7640\n",
            "weighted avg       0.79      0.78      0.78      7640\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81      4752\n",
            "           1       0.67      0.79      0.73      2888\n",
            "\n",
            "    accuracy                           0.78      7640\n",
            "   macro avg       0.77      0.78      0.77      7640\n",
            "weighted avg       0.79      0.78      0.78      7640\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.77      0.80      4643\n",
            "           1       0.68      0.79      0.73      2997\n",
            "\n",
            "    accuracy                           0.77      7640\n",
            "   macro avg       0.77      0.78      0.77      7640\n",
            "weighted avg       0.78      0.77      0.78      7640\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81      4726\n",
            "           1       0.68      0.80      0.73      2914\n",
            "\n",
            "    accuracy                           0.78      7640\n",
            "   macro avg       0.77      0.78      0.77      7640\n",
            "weighted avg       0.79      0.78      0.78      7640\n",
            "\n",
            "Mean F1-score: 0.7804378224618247\n",
            "Mean Accuracy: 0.7778824521337426\n",
            "Mean Precision: 0.78900219893557\n",
            "Mean Recall: 0.7778824521337426\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install xgboost pandas scikit-learn\n",
        "\n",
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load the dataset\n",
        "path = 'ready_to_train_dataset (2).csv'\n",
        "data = pd.read_csv(path)\n",
        "\n",
        "# Drop samples with missing values\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data[['rate', 'review_length', 'readability_score', 'review_subjectivity',\n",
        "          'review_verbs_count', 'review_sentiment', 'Topic1', 'Topic6',\n",
        "          'review_adj_count', 'review_adv_count', 'sum_of_tfidf',\n",
        "          'information giving', 'other']]\n",
        "y = data['response']\n",
        "\n",
        "# Initialize XGBoost classifier\n",
        "model = xgb.XGBClassifier(eval_metric='logloss')\n",
        "\n",
        "# Define hyperparameters grid\n",
        "param_grid = {\n",
        "    'eta': [0.01, 0.1, 0.3],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'n_estimators': [100, 200, 300]\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV with 10-fold cross-validation for hyperparameter tuning\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=5, verbose=1)\n",
        "\n",
        "# Fit the model to find the best hyperparameters\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Best parameters and best score\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best Score: {grid_search.best_score_}\")\n",
        "\n",
        "# Perform 10-fold cross-validation manually to calculate mean F1-score for the predictions\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "f1_scores = []\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "best_estimator = grid_search.best_estimator_\n",
        "\n",
        "for train_index, test_index in cv.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    best_estimator.fit(X_train, y_train)\n",
        "    y_pred = best_estimator.predict(X_test)\n",
        "\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    f1_scores.append(f1)\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "\n",
        "    # Optionally, print classification report for each fold\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate mean and standard deviation of F1-scores, accuracy, precision, and recall\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "\n",
        "print(f\"Mean F1-score: {mean_f1}\")\n",
        "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
        "print(f\"Mean Precision: {mean_precision}\")\n",
        "print(f\"Mean Recall: {mean_recall}\")\n"
      ]
    }
  ]
}