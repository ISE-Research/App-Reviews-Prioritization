{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"thesis_part1_final_preprocess_v1.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"CTy5b_gFWbTO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":326},"outputId":"dd51352e-8dcf-471d-f71b-172fe77227bb"},"source":["!pip install langdetect\n","!pip install pyspellchecker\n","!pip install autocorrect"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (1.0.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect) (1.12.0)\n","Collecting pyspellchecker\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/d1/ec4e830e9f9c1fd788e1459dd09279fdf807bc7a475579fd7192450b879c/pyspellchecker-0.5.4-py2.py3-none-any.whl (1.9MB)\n","\u001b[K     |████████████████████████████████| 1.9MB 4.4MB/s \n","\u001b[?25hInstalling collected packages: pyspellchecker\n","Successfully installed pyspellchecker-0.5.4\n","Collecting autocorrect\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/5b/6510d8370201fc96cbb773232c2362079389ed3285b0b1c6a297ef6eadc0/autocorrect-2.0.0.tar.gz (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 5.2MB/s \n","\u001b[?25hBuilding wheels for collected packages: autocorrect\n","  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for autocorrect: filename=autocorrect-2.0.0-cp36-none-any.whl size=1811641 sha256=6aac27f9f6930ec0d6108e7f14eafb316dff52fda9390af30cc3f28522ba5a45\n","  Stored in directory: /root/.cache/pip/wheels/0b/06/bc/e66f28d72bed29591eadc79cebb2e7964ad0282804ab233da3\n","Successfully built autocorrect\n","Installing collected packages: autocorrect\n","Successfully installed autocorrect-2.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hkn9f1H6hDVj","colab_type":"code","colab":{}},"source":["from langdetect import detect\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from bs4 import BeautifulSoup\n","from spellchecker import SpellChecker\n","import pandas as pd\n","from autocorrect import Speller\n","import gensim\n","from gensim.utils import simple_preprocess\n","from gensim.parsing.preprocessing import STOPWORDS\n","from nltk.stem import WordNetLemmatizer, SnowballStemmer\n","from nltk.stem.porter import *\n","import numpy as np\n","np.random.seed(2018)\n","import nltk\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","from nltk.corpus import stopwords,wordnet\n","from nltk.tokenize import word_tokenize  \n","stop_words = set(stopwords.words('english'))\n","import string\n","import nltk\n","nltk.download('punkt')\n","import string\n","from nltk.corpus import stopwords,wordnet\n","from nltk.tokenize import word_tokenize  \n","stop_words = set(stopwords.words('english'))\n","from nltk.stem import PorterStemmer \n","from nltk.tokenize import word_tokenize\n","from nltk.stem.wordnet import WordNetLemmatizer\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q2tKHAfFYnrJ","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"crJVAaPEYwcq","colab_type":"code","colab":{}},"source":["path = '/content/drive/My Drive/combined_first 19999 reviews.csv'\n","# df = pd.read_csv(path, encoding= 'unicode_escape')\n","# df = pd.read_csv(path,encoding='utf-8')\n","df = pd.read_csv(path, engine='python')\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f74sKcfKfbu_","colab_type":"text"},"source":["#preprocees reviews"]},{"cell_type":"code","metadata":{"id":"efhBh2FRfQKb","colab_type":"code","colab":{}},"source":["def getWordnetPOS(word):\n","    tag = nltk.pos_tag([word])[0][1][0].upper()\n","    tag_dict = {\"J\": wordnet.ADJ,\n","                \"N\": wordnet.NOUN,\n","                \"V\": wordnet.VERB,\n","                \"R\": wordnet.ADV}\n","    return tag_dict.get(tag, wordnet.NOUN)\n","\n","def lemmatize_stemming(text):\n","    return WordNetLemmatizer().lemmatize(text,getWordnetPOS(text))\n","\n","def preprocess(text):\n","    pattern = nltk.re.compile(r\"(.)\\1{2,}\")\n","    check = Speller(lang='en')\n","    ps = PorterStemmer() \n","    result = []\n","    for token in word_tokenize(text):\n","        token=token.lower()\n","        token=ps.stem(token)\n","        token=WordNetLemmatizer().lemmatize(token,'v')\n","        token=pattern.sub(r\"\\1\\1\", token)\n","        token= token.translate(str.maketrans('','',string.punctuation))\n","        if token not in stop_words and len(token) > 1:\n","        # if token not in stop_words:\n","            token=lemmatize_stemming(token)\n","            token=check(token)\n","            result.append(token)\n","    # return result\n","    return (' '.join(result))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B9p80H9agGwD","colab_type":"code","colab":{}},"source":["df['reviews']=df['reviews'].apply(preprocess)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6h7LfQsfkdHa","colab_type":"code","colab":{}},"source":["df.loc[df['response'].isnull(), 'response'] = 0\n","df.loc[df['response']!=0, 'response'] = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BOBwV7RAjUeX","colab_type":"code","colab":{}},"source":["df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pC33EL5_fgFu","colab_type":"text"},"source":["#delete non english reviews row"]},{"cell_type":"code","metadata":{"id":"6toDJIO9bk--","colab_type":"code","colab":{}},"source":["df.drop(df[df['reviews'] ==''].index , inplace=True)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Lm2FZ2ybcNd","colab_type":"code","colab":{}},"source":["from google.colab import  drive\n","drive.mount('/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oJ9I4skxaOVF","colab_type":"code","colab":{}},"source":["df.to_csv('/drive/My Drive/thesis part1 preproceesed_data of combined_first 19999 reviews.csv.csv')"],"execution_count":null,"outputs":[]}]}